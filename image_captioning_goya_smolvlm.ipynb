{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0211e568",
   "metadata": {},
   "source": [
    "# Captioning Goya's work with small language models (SLM)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57de5b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import GPUtil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import PIL\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "import torch\n",
    "\n",
    "# Paths\n",
    "DIRS = {\n",
    "    0: Path(\"data/save\"), # downloaded images\n",
    "    1: Path(\"data/clean\") # processed images\n",
    "}\n",
    "\n",
    "# General purpose functions\n",
    "def flush_cuda():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285a3903",
   "metadata": {},
   "source": [
    "## Retrieving images of Goya's work from Wikidata\n",
    "\n",
    "I retrieved the metadata and images of Goya's work from Wikidata/Wikimedia Commons. If you use this code, please follow Wikidata's User-Agent policy: https://www.wikidata.org/wiki/Wikidata:Data_access\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb07bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import time\n",
    "\n",
    "endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "USER_AGENT = open(\"user_agent.txt\") # Follow Wikidata's User-Agent policy https://www.wikidata.org/wiki/Wikidata:Data_access\n",
    "DOWNLOAD = False  # Download images\n",
    "\n",
    "## Query images from Wikidata with 'creator' (wdt:P170) 'Francisco Goya' (wd:Q5432)\n",
    "query = \"\"\"#Works by Goya\n",
    "#title: Works by Goya\n",
    "#defaultView:ImageGrid\n",
    "SELECT ?item ?itemLabel ?pic ?title ?inception WHERE {\n",
    "  ?item wdt:P170 wd:Q5432;\n",
    "  wdt:P18 ?pic.\n",
    "  OPTIONAL { ?item wdt:P1476 ?title. }\n",
    "  OPTIONAL { ?item wdt:P571 ?inception. }\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],mul,en\". }\n",
    "}\"\"\"\n",
    "\n",
    "\n",
    "def get_results(endpoint_url, query, user_agent):\n",
    "    user_agent = user_agent\n",
    "    sparql = SPARQLWrapper(endpoint_url, agent=user_agent)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    return sparql.query().convert()\n",
    "\n",
    "\n",
    "results = get_results(endpoint_url, query, USER_AGENT)\n",
    "\n",
    "## Donwload images\n",
    "headers = {'User-Agent': USER_AGENT}\n",
    "session = requests.Session()\n",
    "session.headers.update(headers)\n",
    "\n",
    "res = dict()\n",
    "for i, painting in enumerate(results[\"results\"][\"bindings\"]):\n",
    "    uri = painting[\"item\"][\"value\"]\n",
    "    jpg_url = painting[\"pic\"][\"value\"]\n",
    "    id = uri.split('/')[-1] # e.g. 'Q6172289'\n",
    "\n",
    "    file = f'{id}.jpg'\n",
    "    file_path = DIRS[0] / file\n",
    "    \n",
    "    # Cases with unprocessable images\n",
    "    if id in [\"Q1988253\", \"Q17519472\", \"Q20181269\"]:\n",
    "        continue\n",
    "\n",
    "    # Cases with missing inception data\n",
    "    if \"inception\" in painting.keys():\n",
    "        inception = painting[\"inception\"][\"value\"].split(\"T\")[0].split(\"-\")[0]\n",
    "    else:\n",
    "        inception = \"\"\n",
    "\n",
    "    # Cases with missing title or different title languages\n",
    "    if \"title\" in painting.keys():\n",
    "        title_lang = painting[\"title\"][\"xml:lang\"] \n",
    "        title = painting[\"title\"][\"value\"]\n",
    "    else:\n",
    "        title_lang = None\n",
    "\n",
    "    if \"xml:lang\" in painting[\"itemLabel\"].keys():\n",
    "        label_lang = painting[\"itemLabel\"][\"xml:lang\"]\n",
    "    else:\n",
    "        label_lang = \"en\"\n",
    "\n",
    "    # Cases where itemLabel is the id, e.g. 'Q5849545'\n",
    "    label = painting[\"itemLabel\"][\"value\"]\n",
    "    if label==id:\n",
    "        label = \"\"\n",
    "\n",
    "    title_es = \"\"\n",
    "    title_en = \"\"\n",
    "    if title_lang==\"en\":\n",
    "        title_en = title\n",
    "    elif title_lang==\"es\":\n",
    "          title_es = title\n",
    "    elif title_lang == None:\n",
    "        title_en = \"\"\n",
    "        title_es = \"\"\n",
    "    \n",
    "    label_es = \"\"\n",
    "    label_en = \"\"\n",
    "    if label_lang==\"en\":\n",
    "         label_en = label\n",
    "    if label_lang==\"es\":\n",
    "         label_es = label\n",
    "\n",
    "    updates = {\n",
    "        \"id\": id,\n",
    "        \"uri\": uri,\n",
    "        \"file\": file,\n",
    "        \"inception\": inception,\n",
    "        \"title_en\": title_en,\n",
    "        \"title_es\": title_es,\n",
    "        \"label_en\": label_en,\n",
    "        \"label_es\": label_es,\n",
    "        \"caption\": \"\",\n",
    "    }\n",
    "\n",
    "    # Some paintings appear multiple times in 'results', mainly due to several inception dates\n",
    "    if id not in res:\n",
    "        res[id] = updates.copy()\n",
    "    else:\n",
    "        for k, v in updates.items():\n",
    "            if res[id].get(k) in (\"\", None):\n",
    "                 res[id][k] = v\n",
    "    \n",
    "    if DOWNLOAD==True:\n",
    "        try:\n",
    "            r = session.get(jpg_url, stream=True, timeout=30)\n",
    "            r.raise_for_status()\n",
    "            raw = r.content\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                f.write(raw)\n",
    "            time.sleep(0.2)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed {id}\", e)\n",
    "\n",
    "# Store\n",
    "fieldnames = list(list(res.values())[0].keys())\n",
    "res = [v for v in res.values()]\n",
    "with open(DIRS[0]/\"metadata.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    w.writeheader()\n",
    "    w.writerows(res)\n",
    "\n",
    "# Additional cleaning\n",
    "df = pd.read_csv(DIRS[0]/\"metadata.csv\", dtype=\"str\")\n",
    "df['label_en'] = df['label_en'].fillna(df[\"title_en\"])\n",
    "df['label_en'] = df['label_en'].fillna(\"unknown\")\n",
    "df['inception'] = df['inception'].fillna(\"unknown\")\n",
    "df.to_csv(DIRS[0]/\"medata.data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b63077",
   "metadata": {},
   "source": [
    "## Resize images\n",
    "\n",
    "The downloaded images varied greatly in size. I rescaled them so that their longer side measured 512px, matching the input size used to train the image captioning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be028766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.image_utils import load_image\n",
    "\n",
    "MAX_SIZE = 512 # size={\"longest_edge\": N*512} to fit caption model config\n",
    "JPEG_QUALITY = 90\n",
    "\n",
    "def load_and_resize_image(path: Path, max_size: int) -> PIL.Image.Image:\n",
    "    image = load_image(path.__str__())\n",
    "\n",
    "    # Resize large images\n",
    "    w, h = image.size\n",
    "    m = max(w, h)\n",
    "    if m <= max_size:\n",
    "        return image\n",
    "    else:\n",
    "        scale = max_size / m\n",
    "        new_size = (max(1, int(round(w * scale))), max(1, int(round(h * scale)))) \n",
    "        return image.resize(new_size, PIL.Image.LANCZOS)\n",
    "\n",
    "\n",
    "data = pd.read_csv(DIRS[0]/\"metadata.csv\")\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    # Get image\n",
    "    image_path = DIRS[0]/row[\"file\"]\n",
    "    image = load_and_resize_image(image_path, max_size=MAX_SIZE)\n",
    "\n",
    "    # Save\n",
    "    path = DIRS[1]/image_path.name\n",
    "    image.save(\n",
    "        path,\n",
    "        format=\"JPEG\",\n",
    "        quality=JPEG_QUALITY,\n",
    "        optimize=True,\n",
    "        progressive=True,\n",
    "        subsampling=\"4:2:0\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5b4cd6",
   "metadata": {},
   "source": [
    "## Generate image captions\n",
    "\n",
    "I produced image captions using the Hugging Face's SmolVLM-500M-Instruct model: https://huggingface.co/HuggingFaceTB/SmolVLM-500M-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa6f319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText, BitsAndBytesConfig\n",
    "\n",
    "# Free GPU memory\n",
    "try:\n",
    "    del model\n",
    "except NameError:\n",
    "    pass\n",
    "flush_cuda()\n",
    "GPUtil.showUtilization()\n",
    "\n",
    "# Initialize processor and model\n",
    "quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "processor = AutoProcessor.from_pretrained(\"HuggingFaceTB/SmolVLM-500M-Instruct\")\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    \"HuggingFaceTB/SmolVLM-500M-Instruct\",\n",
    "    quantization_config=quantization_config,\n",
    "    attn_implementation=\"sdpa\",\n",
    ")#.to(device)\n",
    "\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66dfc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE = False # replace existing captions in metadata.csv\n",
    "\n",
    "## Set prompt\n",
    "prompt_raw = \"\"\"\n",
    "Describe the objects, people, and background you see \\\n",
    "in the painting or drawing in a factual manner. \n",
    "\"\"\"\n",
    "\n",
    "message = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": prompt_raw},\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "prompt = processor.apply_chat_template(message, add_generation_prompt=True)\n",
    "\n",
    "def make_input(image: PIL.Image.Image, prompt: str):\n",
    "   return processor(text=prompt, images=[image], return_tensors=\"pt\")\n",
    "\n",
    "paths = sorted([p for p in DIRS[1].rglob(\"*\") if p.suffix.lower() in {\".jpg\", \".jpeg\"}])\n",
    "df = pd.read_csv(DIRS[0]/\"metadata.csv\", dtype=str)\n",
    "\n",
    "# Run inference\n",
    "with torch.inference_mode():\n",
    "   for i, p in enumerate(tqdm(paths, total=len(paths))):\n",
    "    \n",
    "    img_id = p.stem\n",
    "    caption_missing = df.loc[df[\"id\"]==img_id, \"caption\"].isna().any()\n",
    "\n",
    "    if REPLACE or caption_missing:\n",
    "        with PIL.Image.open(p) as image:\n",
    "            inputs = make_input(image, prompt).to(device)\n",
    "\n",
    "        gen_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=200,\n",
    "            num_beams=4,\n",
    "            repetition_penalty=1.15,\n",
    "            do_sample=False,\n",
    "            #use_cache=False,\n",
    "            output_attentions=False,\n",
    "            output_hidden_states=False,\n",
    "            return_dict_in_generate=False,\n",
    "        )\n",
    "\n",
    "        gen_text = processor.batch_decode(\n",
    "            gen_ids,\n",
    "            skip_special_tokens=True,\n",
    "        )[0].split(\"Assistant:\")[1].strip()\n",
    "        \n",
    "        df.loc[df[\"id\"]==img_id, \"caption\"] = gen_text\n",
    "        del inputs, gen_ids\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    if i % 5 == 0:\n",
    "        df.to_csv(DIRS[0]/\"metadata.csv\", index=False)\n",
    "\n",
    "# Save\n",
    "df.to_csv(DIRS[0]/\"metadata.csv\", index=False)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "df.to_csv(DIRS[0]/f\"metadata_{timestamp}.csv\", index=False) # to avoid overwriting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8db8350",
   "metadata": {},
   "source": [
    "## Example output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3146fc19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .img-grid {\n",
       "            display: grid;\n",
       "            grid-template-columns: repeat(2, minmax(0, 1fr));\n",
       "            gap: 8px;\n",
       "        }\n",
       "        .card {\n",
       "            background: white;\n",
       "            padding: 6px;\n",
       "            color: black; \n",
       "        }\n",
       "    </style>\n",
       "    <div class=\"img-grid\">\n",
       "        <div class=\"card\">\n",
       "            <img src=\"data/clean/Q64956388.jpg\" loading=\"lazy\" style=\"width:auto; height:400px; object-fit:contain; display:block; margin-left:auto; margin-right:auto;\"/>\n",
       "            <div style=\"padding:0 8px;\">Title: Asta su abuelo (And So Was His Grandfather).</div> \n",
       "            <div style=\"padding:0 8px;\">Wikidata ID: Q64956388</div>\n",
       "            <div class=\"caption\" style=\"max-heigt:200px; overflow:auto; padding:8px;\">AI-generated caption:<Br>            The image is a black-and-white drawing or painting of a donkey reading a book. The donkey is depicted in a seated position, wearing a long-sleeved shirt and pants. The donkey&#x27;s ears are perked up, and it appears to be engaged in reading the book, which is held in its mouth. The donkey&#x27;s expression is calm and focused, as if it is absorbed in the content of the book.\n",
       "\n",
       "In the background, there is a plain, neutral-toned wall, which provides a stark contrast to the donkey and the book. There are no other objects or figures in the image, keeping the focus solely on the donkey and the book.\n",
       "\n",
       "The drawing is done in a realistic style, with fine lines and shading to create depth and dimension. The donkey&#x27;s fur is detailed, and the texture of its skin is discernible, giving it a lifelike appearance. The donkey&#x27;s posture and the way it holds the book suggest that it might be</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"card\">\n",
       "            <img src=\"data/clean/Q64956396.jpg\" loading=\"lazy\" style=\"width:auto; height:400px; object-fit:contain; display:block; margin-left:auto; margin-right:auto;\"/>\n",
       "            <div style=\"padding:0 8px;\">Title: Ni mas ni menos (Neither More nor Less).</div> \n",
       "            <div style=\"padding:0 8px;\">Wikidata ID: Q64956396</div>\n",
       "            <div class=\"caption\" style=\"max-heigt:200px; overflow:auto; padding:8px;\">AI-generated caption:<Br>            The image is a black-and-white drawing or painting. In the foreground, there is a kangaroo sitting on its haunches. The kangaroo appears to be looking down at a human who is kneeling on the ground in front of it. The human is wearing a hat and appears to be interacting with the kangaroo. In the background, there is a structure that looks like a barrel or a barrel-like object. There is text at the bottom of the image that reads &quot;Ni mea ni menos,&quot; which translates to &quot;No, no, no&quot; in English.\n",
       "\n",
       "### Analysis and Description:\n",
       "\n",
       "1. **Subjects and Objects**:\n",
       "   - **Kangaroo**: The kangaroo is the main subject of the image. It is depicted in a squatting position, facing the human who is kneeling.\n",
       "   - **Human**: The human is kneeling on the ground in front of the kangaroo. He is wearing a hat and appears to be interacting with the kangaroo.</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"card\">\n",
       "            <img src=\"data/clean/Q59260209.jpg\" loading=\"lazy\" style=\"width:auto; height:400px; object-fit:contain; display:block; margin-left:auto; margin-right:auto;\"/>\n",
       "            <div style=\"padding:0 8px;\">Title: Queen of Spain Maria Louisa, n√©e Bourbon-Parma.</div> \n",
       "            <div style=\"padding:0 8px;\">Wikidata ID: Q59260209</div>\n",
       "            <div class=\"caption\" style=\"max-heigt:200px; overflow:auto; padding:8px;\">AI-generated caption:<Br>            The image depicts a portrait of a woman, likely from the 18th century, based on her attire and the style of the painting. The woman is positioned in the center of the frame, facing slightly to the right, with her head slightly tilted to the left. She has a serene expression on her face, with her eyes looking directly at the viewer. Her hair is styled in an elaborate manner, adorned with a large, wide-brimmed hat adorned with feathers and a blue ribbon. The hat appears to be made of fabric, possibly silk or a similar material, and has a high crown.\n",
       "\n",
       "The woman is wearing a corseted bodice with a corseted skirt that flows loosely around her body. The bodice is adorned with gold and silver embroidery, featuring intricate patterns and designs. She is also wearing a necklace with a pendant in the shape of a cross, which is a common symbol of Christianity.\n",
       "\n",
       "The background of the painting is dark</div>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from helpers import show_images\n",
    "\n",
    "df = pd.read_csv(DIRS[0]/\"metadata.csv\")         \n",
    "ids = [\"Q59260209\", \"Q64956388\", \"Q64956396\"]\n",
    "df_sample = df[df['id'].isin(ids)]\n",
    "\n",
    "show_images(df_sample, DIRS[1], img_height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d135a9d",
   "metadata": {},
   "source": [
    "## Semantic search with embeddings\n",
    "\n",
    "I embedded the produced descriptions into a vector space for semantic search using the multi-qa-mpnet-base-dot-v1 model: https://huggingface.co/sentence-transformers/multi-qa-mpnet-base-dot-v1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e7e58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Prepare database\n",
    "df = pd.read_csv(DIRS[0]/\"metadata.csv\", dtype=\"str\")\n",
    "df['label_en'] = df['label_en'].fillna(df[\"title_en\"])\n",
    "df['label_en'] = df['label_en'].fillna(\"unknown\")\n",
    "df['inception'] = df['inception'].fillna(\"unknown\")\n",
    "\n",
    "data = Dataset.from_pandas(df)\n",
    "def concatenate_text(row):\n",
    "    return {\n",
    "        #\"text\": \"Title: \" + row['label_en'] \n",
    "        #+ \"\\n Year: \" + str(row['inception'])\n",
    "        #+ \"\\n Caption: \" + row['caption']\n",
    "        \"text\": \"Caption: \" + row['caption'] # search the caption only\n",
    "    }\n",
    "data = data.map(concatenate_text)\n",
    "\n",
    "# Free GPU memory\n",
    "try:\n",
    "    del model\n",
    "except NameError:\n",
    "    pass\n",
    "flush_cuda()\n",
    "\n",
    "# Initialize tokenizer and model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_ID = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModel.from_pretrained(MODEL_ID).to(device)\n",
    "\n",
    "# Pool embedding dimensions\n",
    "def cls_pooling(model_output):\n",
    "    return model_output.last_hidden_state[:, 0]\n",
    "\n",
    "def get_embeddings(text_list):\n",
    "    encoded_input = tokenizer(\n",
    "        text_list, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    encoded_inputs = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "    model_output = model(**encoded_inputs)\n",
    "    return cls_pooling(model_output)\n",
    "\n",
    "\n",
    "# Calculate embeddings\n",
    "embeddings = data.map(\n",
    "    lambda x: {\"embeddings\": get_embeddings(x[\"text\"]).detach().cpu().numpy()[0]}\n",
    ")\n",
    "\n",
    "# Add FAISS index\n",
    "_ = embeddings.add_faiss_index(column=\"embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7ac49d",
   "metadata": {},
   "source": [
    "## Query the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e11478bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .img-grid {\n",
       "            display: grid;\n",
       "            grid-template-columns: repeat(2, minmax(0, 1fr));\n",
       "            gap: 8px;\n",
       "        }\n",
       "        .card {\n",
       "            background: white;\n",
       "            padding: 6px;\n",
       "            color: black; \n",
       "        }\n",
       "    </style>\n",
       "    <div class=\"img-grid\">\n",
       "        <div class=\"card\">\n",
       "            <img src=\"data/clean/Q3211825.jpg\" loading=\"lazy\" style=\"width:auto; height:300px; object-fit:contain; display:block; margin-left:auto; margin-right:auto;\"/>\n",
       "            <div style=\"padding:0 8px;\">Title: Banderillas en el campo.</div> \n",
       "            <div style=\"padding:0 8px;\">Wikidata ID: Q3211825</div>\n",
       "            <div class=\"caption\" style=\"max-heigt:200px; overflow:auto; padding:8px;\">AI-generated caption:<Br>            The image depicts a scene from a historical or fantasy battle. In the foreground, there is a large, brown bull with a long, curved horn on its forehead. The bull is running towards the viewer, its head lowered as if it is about to charge. Behind the bull, there is a group of people, some of whom are mounted on horses. They appear to be engaged in combat, with some of them wielding weapons such as swords and spears.\n",
       "\n",
       "To the left side of the image, there is a group of people, some of whom are mounted on horses and others on foot. They seem to be preparing for battle, with some of them dressed in armor and others in casual clothing. In the background, there is a fortified structure, possibly a castle or a fortress, with a gate that is open. Beyond the gate, there is a landscape with rolling hills and trees, suggesting that the battle is taking place in a rural or semi-rural area.\n",
       "\n",
       "The</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"card\">\n",
       "            <img src=\"data/clean/Q64956270.jpg\" loading=\"lazy\" style=\"width:auto; height:300px; object-fit:contain; display:block; margin-left:auto; margin-right:auto;\"/>\n",
       "            <div style=\"padding:0 8px;\">Title: Caida de un picador de su caballo debajo del toro (A Picador is Unhorsed and Falls under the Bull).</div> \n",
       "            <div style=\"padding:0 8px;\">Wikidata ID: Q64956270</div>\n",
       "            <div class=\"caption\" style=\"max-heigt:200px; overflow:auto; padding:8px;\">AI-generated caption:<Br>            The image appears to be a black-and-white drawing or painting. The primary subject of the image is a bull. The bull is depicted in mid-action, with its head turned to the left, as if it is about to charge. The bull has a large, muscular body with a distinctive hump on its back. The bull&#x27;s horns are prominent and appear to be well-defined.\n",
       "\n",
       "In the foreground of the image, there are several human figures. These figures appear to be engaged in combat with the bull. The human figures are dressed in period clothing, which suggests that the scene might be set in a historical context, possibly during the 18th or 19th century. The human figures include men and women, and they seem to be in various poses of action, such as running, leaping, or wielding weapons.\n",
       "\n",
       "The background of the image is plain and unadorned, with no additional elements or decorations. There are no other</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"card\">\n",
       "            <img src=\"data/clean/Q64956282.jpg\" loading=\"lazy\" style=\"width:auto; height:300px; object-fit:contain; display:block; margin-left:auto; margin-right:auto;\"/>\n",
       "            <div style=\"padding:0 8px;\">Title: Pedro Romero matando a toro parado (Pedro Romero Killing the Halted Bull).</div> \n",
       "            <div style=\"padding:0 8px;\">Wikidata ID: Q64956282</div>\n",
       "            <div class=\"caption\" style=\"max-heigt:200px; overflow:auto; padding:8px;\">AI-generated caption:<Br>            The image is a black-and-white drawing or painting depicting two figures engaged in a physical confrontation with a bull. The figures appear to be in mid-action, with the one on the left holding a long stick, possibly a spear, while the one on the right holds the bull by the horns. The bull is depicted as a large, muscular animal with large horns protruding from its head.\n",
       "\n",
       "In the background, there are several other figures, some of whom appear to be engaged in a similar physical confrontation with the bull. This suggests that the scene is taking place in a controlled environment, possibly a bullring or arena, where such confrontations are common.\n",
       "\n",
       "The setting appears to be outdoors, as indicated by the natural elements around the figures. The ground is rough and uneven, typical of a dirt or gravel surface, which is common in bullfighting arenas.\n",
       "\n",
       "The figures in the image are dressed in traditional bullfighting attire, which includes long-sleeved</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"card\">\n",
       "            <img src=\"data/clean/Q64956236.jpg\" loading=\"lazy\" style=\"width:auto; height:300px; object-fit:contain; display:block; margin-left:auto; margin-right:auto;\"/>\n",
       "            <div style=\"padding:0 8px;\">Title: Desjarrete de la canalla con lanzas, medias-lunas, banderillas y otras armas (The Rabble Hamstring the Bull with Lances, Sickles, Banderillas and Other Arms).</div> \n",
       "            <div style=\"padding:0 8px;\">Wikidata ID: Q64956236</div>\n",
       "            <div class=\"caption\" style=\"max-heigt:200px; overflow:auto; padding:8px;\">AI-generated caption:<Br>            The image is a black-and-white drawing or painting depicting a battle scene. The central focus is a large, dark brown bull with horns protruding from its head. The bull appears to be in mid-stride, with its front legs slightly bent and its hind legs fully extended. The bull&#x27;s body is muscular and well-defined, suggesting it is a powerful animal.\n",
       "\n",
       "In the background, several human figures are engaged in combat with the bull. The human figures are dressed in traditional clothing, which includes tunics and breeches. They are armed with various weapons, including spears and bows and arrows. The human figures are in dynamic poses, suggesting they are actively engaged in the battle.\n",
       "\n",
       "To the left side of the image, there is another human figure holding a spear. This figure appears to be in a defensive stance, possibly aiming the spear at the bull.\n",
       "\n",
       "In the background, there are additional human figures, some of whom are also engaged in combat with the bull</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"card\">\n",
       "            <img src=\"data/clean/Q65223795.jpg\" loading=\"lazy\" style=\"width:auto; height:300px; object-fit:contain; display:block; margin-left:auto; margin-right:auto;\"/>\n",
       "            <div style=\"padding:0 8px;\">Title: La desgraciada muerte de Pepe Illo en la plaza de Madrid (The Unlucky Death of Pepe Illo in the Ring at Madrid).</div> \n",
       "            <div style=\"padding:0 8px;\">Wikidata ID: Q65223795</div>\n",
       "            <div class=\"caption\" style=\"max-heigt:200px; overflow:auto; padding:8px;\">AI-generated caption:<Br>            The image is a black-and-white pencil drawing or painting. The primary subject of the image is a scene involving a bull and two men. The bull is positioned in the foreground, facing the viewer, with its head lowered towards the ground. The bull has a large, muscular body with a distinctive hump on its back, indicative of a bull species.\n",
       "\n",
       "In the center of the image, two men are engaged in a physical altercation with the bull. The man on the left appears to be attempting to push the bull forward, while the man on the right is attempting to hold the bull back. Both men are dressed in traditional clothing, which suggests that the scene might be set in a rural or semi-rural environment.\n",
       "\n",
       "The background of the image is composed of a plain, flat surface, possibly a wall or a large piece of furniture. There are no other objects or figures in the background, keeping the focus solely on the central subjects.\n",
       "\n",
       "The drawing is</div>\n",
       "        </div>\n",
       "        \n",
       "        <div class=\"card\">\n",
       "            <img src=\"data/clean/Q64956205.jpg\" loading=\"lazy\" style=\"width:auto; height:300px; object-fit:contain; display:block; margin-left:auto; margin-right:auto;\"/>\n",
       "            <div style=\"padding:0 8px;\">Title: Picador Caught by a Bull.</div> \n",
       "            <div style=\"padding:0 8px;\">Wikidata ID: Q64956205</div>\n",
       "            <div class=\"caption\" style=\"max-heigt:200px; overflow:auto; padding:8px;\">AI-generated caption:<Br>            The image is a black-and-white drawing or painting. In the foreground, there are two men on horseback. The man on the left is holding a spear, while the man on the right is holding a shield. In the middle of the image, there is a large bull. The bull has horns and is rearing up on its hind legs. In the background, there is a crowd of people, some of whom are sitting on the ground and some of whom are standing. The people in the background appear to be engaged in a battle or some sort of conflict.</div>\n",
       "        </div>\n",
       "        </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from helpers import show_images\n",
    "\n",
    "query = \"Scenes of a bull fight\"\n",
    "n_results = 6 # number of results\n",
    "\n",
    "query_embd = get_embeddings([query]).cpu().detach().numpy()\n",
    "scores, samples = embeddings.get_nearest_examples(\n",
    "    \"embeddings\", query_embd, k=n_results\n",
    ")\n",
    "\n",
    "samples_df = pd.DataFrame.from_dict(samples)\n",
    "samples_df[\"scores\"] = scores\n",
    "samples_df.sort_values(\"scores\", ascending=True, inplace=True)\n",
    "\n",
    "show_images(samples_df, DIRS[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
